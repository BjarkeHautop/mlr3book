---
author:
  - name: Lennart Schneider
    orcid: 0000-0003-4152-5308
    email: lennart.schneider@stat.uni-muenchen.de
    affiliations:
      - name: Ludwig-Maximilians-Universität München
abstract:
  Bla.
---

# Bayesian Optimization {#sec-bayesian-optimization}

```{r}
set.seed(2906)
```

{{< include _setup.qmd >}}

Black-box optimization considers the optimization of a so-called black-box function whose structure and analytical description is unknown, unexploitable or non-existent.
As a result, the only information available is the output value of the function given an input value.
Examples range from real-life experiments, e.g., crash tests or chemical reactions to computer simulations, e.g., the design of a helicopter rotor blade.
Moreover, HPO (see @sec-optimization) is a prime example for black-box optimization.
Recall that in HPO, we configure a learner with a hyperparameter configuration and evaluate the model via a resampling technique to measure its performance with the goal to find the optimal hyperparameter configuration.
In general no analytical description exists for this mapping from a hyperparameter configuration to performance and gradient information is not available.
Besides, evaluating the performance of a learner can take a substantial amount of time, making HPO an expensive black-box optimization problem calling for sample efficient optimization methods.
Detailed introductions to black-box optimization and Bayesian Optimization are given in @hpo_practical,@hpo_automl and @garnett_2022.

In this section, we will give a brief general introduction to black-box Optimization making use of the `r bbotk`\index{bbotk} package.
We then show how Bayesian Optimization can be performed within the mlr3 ecosystem making use of the `r mlr3mbo`\index{mlr3mbo} package.

## Black-Box Optimization {#sec-black-box-optimization}

The `r bbotk` package is the workhorse package for black-box optimization within the mlr3 ecosystem.
At the heart of the package are the R6 classes

* `r ref("OptimInstanceSingleCrit")` and `r ref("OptimInstanceMultiCrit")`, which are used to construct an optimization 'instance' which describes the optimization problem and stores the results; and
* `r ref("Optimizer")` which is used to get and set optimization algorithms.

This should sound very familiar.
Indeed, in @sec-optimization, the classes `r ref("TuningInstanceSingleCrit")`, `r ref("TuningInstanceMultiCrit")` and `r ref("Tuner")` were already introduced.
Those three R6 classes essentially build upon `r ref("OptimInstanceSingleCrit")`, `r ref("OptimInstanceMultiCrit")` and `r ref("Optimizer")` which are the more general black-box optimization base classes.

Our running example will be to optimize the 2D Ackley function which is characterized by a comparably flat outer region, and a deep hole in the centre.
The many local optima pose a risk for many optimization algorithms to get stuck.

At the core of an `r ref("OptimInstanceSingleCrit")` lies an `r ref("Objective")` function wrapping the function, domain and codomain.
Objective functions can be constructed using the classes `r ref("ObjectiveRFun")` (wraps a custom R function that expects a list as input), `r ref("ObjectiveRFunMany")` (wraps a custom R function that expects a list of configurations as input) or `r ref("ObjectiveRFunDt")` (wraps a custom R function that works on a `r ref("data.table")`).
In the following, we will use `r ref("ObjectiveRFunDt")`.
FIXME: problem with ackley_2D is its strong global structure, often the EI will not be multimodal later

```{r}
ackley_2D = function(xdt) {
  y = - 20 * exp(-0.2 * sqrt(rowSums(xdt^2) / 2)) - 
    exp(rowSums(cos(2 * pi * xdt)) / 2) + 20 + exp(1)
  data.table(y = y)
}
```

The global minimum is located at the origin:
```{r}
ackley_2D(data.table(x1 = 0, x2 = 0))
```

An `r ref("Objective")` always requires the specification of the domain and codomain in the form of a `r ref("ParamSet")`:

```{r}
domain = ps(x1 = p_dbl(lower = -32.768, upper = 32.768),
  x2 = p_dbl(lower = -32.768, upper = 32.768))
codomain = ps(y = p_dbl(tags = "minimize"))
objective = ObjectiveRFunDt$new(ackley_2D,
  domain = domain, codomain = codomain)
```

We can proceed to visualize the 2D Ackley function:

```{r}
xydt = generate_design_grid(domain, resolution = 101)$data
xydt[, y := objective$eval_dt(xydt)$y]
```

```{r}
library(ggplot2)
ggplot(aes(x = x1, y = x2, z = y), data = xydt) +
  geom_contour_filled() +
  theme_minimal()
```

By wrapping the objective in an `r ref("OptimInstanceSingleCrit")` we can proceed to optimize the 2D Ackley function:

```{r, output=FALSE}
instance = OptimInstanceSingleCrit$new(objective,
  terminator = trm("evals", n_evals = 30))
optimizer = opt("random_search", batch_size = 30)
optimizer$optimize(instance)
```

```{r}
instance$archive$best()
```

We probably can do better than a simple random search by using a more sophisticated optimizer.
To see all available optimizers you can inspect the following dictionary:

```{r}
as.data.table(mlr_optimizers)
```

## Building Blocks of Bayesian Optimization {#sec-bayesian-optimization-blocks}

Bayesian Optimization (BO) is an iterative optimization algorithm that makes use of a so-called surrogate to model the unknown black-box function.
After having observed an initial design of observations, the surrogate model is trained on all data points observed so far and a so-called acquisition function is used to determine which points of the search space are promising candidates that should be evaluated next.
The acquisition function relies on the prediction of the surrogate model and requires no evaluation of the true black-box function and therefore is comparably cheap to optimize.
After having evaluated the next candidate, the process repeats itself until a given termination criteria is met.

Most BO flavors therefore follow a simple loop:

    1. Fit the surrogate model on all observations made so far.
    2. Optimize the acquisition function to find the next candidate that should be evaluated.
    3. Evaluate the next candidate.

`r mlr3mbo` makes BO available within the mlr3 ecosystem.
At the heart of the package are the two R6 classes `r ref("OptimizerMbo")` and `r ref("TunerMbo")` which can be configured with respect to their `r ref("loop_function")` (determining the general loop structure of the BO algorithm), `r ref("Surrogate")` (surrogate model), `r ref("AcqFunction")` (acquisition function) and `r ref("AcqOptimizer")` (acquisition function optimizer).

### The Initial Design

Before we can fit a surrogate model, we need data.
The initial design refers of the first set of points the black-box functions was evaluated on before BO algorithms start their loop.

`r mlr3mbo` offers two different ways for specifying an initial design:
    1. One can simply evaluate points on the `OptimInstance` that is to be optimized prior to using an `OptimizerMbo`. In this case, the `loop_function` should skip the construction and evaluation of an initial design.
    2. If no points were already evaluated on the `OptimInstance`, the `loop_function` should construct an initial design itself and evaluate it, e.g., `bayesopt_ego` in this scenario constructs and initial design of size 4D where D is the dimensionality of the search space by sampling points uniformly at random.

Functions for creating different initial designs are part of the `r paradox` package, e.g.:

1. `r ref("generate_design_random")`: uniformly at random
1. `r ref("generate_design_grid")`: uniform sized grid
1. `r ref("generate_design_lhs")`: Latin hypercube sampling
1. `r ref("generate_design_sobol")`: Sobol sequence

### Loop Function

The `r ref("loop_function")` determines the behavior of the BO algorithm on a global level, i.e., how the subroutine should look like that is performed at each iteration.

To get an overview of readily available loop functions, the following dictionary can be inspected:

```{r}
as.data.table(mlr_loop_functions)
```

Technically, all `loop_function`s are members of the `S3` class `r ref("loop_function")`, and are simply decorated `r ref("base::function", "functions")`.

After having made some assertions and safety checks, and having evaluated the initial design, `r ref("mlr_loop_functions_ego", "bayesopt_ego")` essentially only performs the following steps:

1. `acq_function$surrogate$update()`: updates the surrogate model
2. `acq_function$update()`: updates the acquisition function
3. `acq_optimizer$optimize()`: optimizes the acquisition function to yield a new candidate

### Surrogate

A surrogate encapsulates a regression learner that models the unknown black-box function based on observed data.
In `r mlr3mbo`, `r ref("SurrogateLearner")` and `r ref("SurrogateLearnerCollection")` are the higher-level R6 classes which should be used to construct a surrogate, inheriting from the base `r ref("Surrogate")` class.

As a learner, any `r ref("LearnerRegr", "regression learner")` from `r "mlr3"` can be used, however, most acquisition functions require both a mean and a variance prediction (therefore not all learners are suitable for all scenarios).
Typical choices include:

* A `r ref("mlr3learners::mlr_learners_regr.km", "Gaussian Process")` for low dimensional numeric search spaces
* A `r ref("mlr3learners::mlr_learners_regr.ranger", "Random Forest")` for higher dimensional mixed (and / or hierarchical) search spaces

A `SurrogateLearner` can be constructed via:

```{r}
surrogate = srlrn(lrn("regr.km"))
```

The encapsulated learner can be accessed via the `$model` field:

```{r}
surrogate$model
```

Internally, the learner is fitted on a `r ref("mlr3::TaskRegr", "regression task")` constructed from the `r ref("bbotk::Archive", "Archive")` of the `r ref("bbotk::OptimInstance", "OptimInstance")` that is to be optimized.
Depending on the choice of the loop function, multiple targets must be modelled by multiple surrogates, in which case a `r ref("SurrogateLearnerCollection")` should be used, see, e.g., @sec-multi-objective-bayesian-optimization.

### Acquisition Function

Based on a surrogate, an acquisition function quantifies the attractiveness of each point of the search space if it were to be evaluated in the next iteration.

A popular example is given by the Expected Improvement [@jones_1998]:

$$
\mathbb{E}_{y} \left[ \max \left( f_{\mathrm{min}} - y, 0 \right) \right]
$$
Here, $y$ is the surrogate prediction for a given point $x$ (which when using a Gaussian Process follows a normal distribution) and $f_{\mathrm{min}}$ is the currently best function value observed so far (when assuming minimization).

To get an overview of available acquisition functions, the following dictionary can be inspected:

```{r}
as.data.table(mlr_acqfunctions)
```

Technically, all acquisition functions inherit from the `R6` class `r ref( "mlr3mbo::AcqFunction", "AcqFunction")` which itself simply inherits from the base `r ref("bbotk::Objective", "Objective")` class.

Construction is straightforward via:

```{r}
acq_function = acqf("ei")
```

### Acquisition Function Optimizer

To find the most promising candidate for evaluation, the acquisition function itself must be optimized.
Internally, an `r ref("OptimInstance")` is constructed using the acquisition function as an `r ref("bbotk::Objective", "Objective")`.

An acquisition function optimizer is then used to solve this optimization problem.
Technically, this optimizer is a member of the `r ref("mlr3mbo::AcqOptimizer", "AcqOptimizer")` `R6` class.

Construction requires specifying an `r ref("bbotk::Optimizer", "Optimizer")` as well as a `r ref( "bbotk::Terminator", "Terminator")`:

```{r}
acq_optimizer = acqo(opt("random_search", batch_size = 1000),
  terminator = trm("evals", n_evals = 1000))
```

## Putting Everything Together

After having introduced all building blocks, we now want to manually perform sequential single-objective Bayesian Optimization (i.e., what `r ref("mlr_loop_functions_ego", "bayesopt_ego")`) does.

First, we reset the `archive` of the instance, and generate and evaluate an initial design:

```{r}
instance$archive$clear()
design = generate_design_random(instance$search_space, n = 8L)$data
instance$eval_batch(design)
```

We then create a surrogate and train it on all observed data:

```{r, output=FALSE}
surrogate = srlrn(lrn("regr.km", covtype = "matern3_2", optim.method = "gen"),
  archive = instance$archive)
surrogate$update()
```

The following plot visualizes the mean and variance prediction of the surrogate.
Note that when using a Gaussian Process that interpolates the training data, the variance prediction is zero for training data.
The initial design is coloured in red.

```{r}
xydt[, c("mean", "variance") := surrogate$predict(xydt[, surrogate$x_cols, with = FALSE])]
ggplot() +
  geom_contour_filled(aes(x = x1, y = x2, z = mean), data = xydt) +
  geom_point(aes(x = x1, y = x2), colour = "darkred", data = instance$archive$data) +
  labs(title = "Mean Prediction") +
  theme_minimal()
ggplot() +
  geom_contour_filled(aes(x = x1, y = x2, z = variance), data = xydt) +
  geom_point(aes(x = x1, y = x2), colour = "darkred", data = instance$archive$data) +
  labs(title = "Variance Prediction") +
  theme_minimal()
```

We now use the Expected Improvement to choose the next candidate for evaluation:

```{r}
acq_function = acqf("ei", surrogate = surrogate)
acq_function$update()
xydt[, "ei" := acq_function$eval_dt(xydt[, surrogate$x_cols, with = FALSE])]
```

The following plot shows that the Expected Improvement is high in regions where the mean prediction is low but the variance prediction still suggested some variance:

```{r}
ggplot() +
  geom_contour_filled(aes(x = x1, y = x2, z = ei), data = xydt) +
  geom_point(aes(x = x1, y = x2), colour = "darkred", data = instance$archive$data) +
  labs(title = "Expected Improvement") +
  theme_minimal()
```

Based on an acquisition function optimizer we now optimize the Expected Improvement (of course we also could have picked the next candidate based on the grid we used to generate the plot but in a real BO setting we probably would choose a more sophisticated optimizer, e.g., the DIRECT algorithm provided by the `nloptr` package):
FIXME link

```{r}
acq_optimizer = acqo(opt("nloptr", algorithm = "NLOPT_GN_ORIG_DIRECT"),
  terminator = trm("stagnation", iters = 100, threshold = 1e-5),
  acq_function = acq_function)
candidate = acq_optimizer$optimize()
```

```{r}
ggplot() +
  geom_contour_filled(aes(x = x1, y = x2, z = ei), data = xydt) +
  geom_point(aes(x = x1, y = x2), colour = "darkred", data = instance$archive$data) +
  geom_point(aes(x = x1, y = x2), colour = "white", size = 2, data = candidate) +
  labs(title = "Next Candidate in white") +
  theme_minimal()
```

We proceed to evaluate the candidate and would continue with the next iteration of the loop.

```{r}
instance$eval_batch(candidate)
```

## Bayesian Optimization for Black-Box Optimization {#sec-bayesian-black-box-optimization}

Of course, you usually do not want to perform all steps of the BO loop manually.
Instead you simply construct an `r ref("OptimizerMbo")` and use it to optimize the instance.
Note that when not using `r mlr3mbo` interactively, passing arguments such as `archive` to the `surrogate` is not required:

```{r}
surrogate = srlrn(lrn("regr.km", covtype = "matern3_2", optim.method = "gen"))
acq_function = acqf("ei")
acq_optimizer = acqo(opt("nloptr", algorithm = "NLOPT_GN_ORIG_DIRECT"),
  terminator = trm("stagnation", iters = 100, threshold = 1e-5))
optimizer = opt("mbo",
  loop_function = bayesopt_ego,
  surrogate = surrogate,
  acq_function = acq_function,
  acq_optimizer = acq_optimizer)
```

```{r, output=FALSE}
instance$archive$clear()
optimizer$optimize(instance)
```

```{r}
instance$archive$best()
```

We see that BO is much more sample efficient and comes close to the true global optimum using only 30 function evaluations.

FIXME: Figure mit RS, CMAES, BO wie in lecture?

FIXME: show the parameters of the optimizer? State that loop_function, surrogate, acq_function and acq_optimizer are fields and not params
       discuss result function, discuss how to pass arguments to the loop?

## Bayesian Optimization for Hyperparameter Optimization {#sec-bayesian-tuning}

FIXME: discuss with Bernd objective of tuning instance has property noisy --> therefore mlr3mbo treats it noisy and will change its default (e.g., GP); and mostly relevant the result function
FIXME: issue in mlr3mbo with results functions (populate the field always!, rename result_by_default, allow surrogate argument for result_by_surrogate
FIXME: note about defaults and safety nets and extending; separate chapters? note about extending --> maybe in a last technical subchapter?

`r mlr3mbo` can be used out of the box for HPO within the mlr3 ecosystem using a `r ref("TunerMbo")`.
For illustrative purposes, we revisit the tuning example of @sec-tuning-instance and perform BO.

First, we construct the tuning instance:

```{r}
resampling = rsmp("cv", folds = 3)

measure = msr("classif.ce")

learner = lrn("classif.svm",
  cost  = to_tune(1e-5, 1e5, logscale = TRUE),
  gamma = to_tune(1e-5, 1e5, logscale = TRUE),
  kernel = "radial",
  type = "C-classification"
)

instance = ti(
  task = tsk("sonar"),
  learner = learner,
  resampling = rsmp("cv", folds = 3),
  measures = msr("classif.ce"),
  terminator = trm("evals", n_evals = 25)
)
```

We can then simply construct an `r ref("TunerMbo")` and use it to optimize the instance:

```{r}
tuner = tnr("mbo",
  loop_function = bayesopt_ego,
  surrogate = surrogate,
  acq_function = acq_function,
  acq_optimizer = acq_optimizer)

```

```{r, output=FALSE}
tuner$optimize(instance)
```

We see that BO finds a substantially better hyperparameter configuration than the grid search (using the same budget):

```{r}
instance$result
```

FIXME: some notes about noisy here

## Multi-Objective Bayesian Optimization {#sec-multi-objective-bayesian-optimization}

BO cannot only be used to optimize single-objective black-box functions but also multi-objective black-box functions.
Multi-Objective BO algorithms can differ in many ways, for example whether they use a scalarization approach of
objectives and only rely on a single surrogate or fit a surrogate for each objective.
More details on multi-objective BO can for example be found in @hpo_multi.

FIXME: discuss with bernd whether ParEGO or smsego. then introduce either algorithm briefly

We will now illustrate how ParEGO can be used for multi-objective HPO and revisit the example of @sec-multi-metrics-tuning:

```{r}
learner = lrn("classif.rpart",
  cp = to_tune(1e-04, 1e-1, logscale = TRUE),
  minsplit = to_tune(2, 128, logscale = TRUE),
  maxdepth = to_tune(1, 30)
)

measures = msrs(c("classif.ce", "selected_features"))

instance = ti(
  task = tsk("spam"),
  learner = learner,
  resampling = rsmp("cv", folds = 3),
  measures = measures,
  terminator = trm("evals", n_evals = 20),
  store_models = TRUE  # required to inspect selected_features
)


```

FIMXE: random search below ist needed due to nloptr not supporting integers params

```{r}
surrogate = srlrn(lrn("regr.km", covtype = "matern3_2", optim.method = "gen"))
acq_function = acqf("ei")
acq_optimizer = acqo(opt("random_search", batch_size = 1000),
  terminator = trm("evals", n_evals = 1000))

tuner = tnr("mbo",
  loop_function = bayesopt_parego,
  surrogate = surrogate,
  acq_function = acq_function,
  acq_optimizer = acq_optimizer)
tuner$result_function = result_by_default
```

```{r, output=FALSE}
tuner$optimize(instance)
```

FIXME: without tuner$result_function = result_by_default this fails because result_by_surrogate_design naturally does not work with the parego surrogate (1 surrogate vs 2 objectives)

```{r}
library(viridisLite)
ggplot(instance$archive$best(), aes(x = selected_features, y = classif.ce)) +
  geom_step(
    direction = "vh",
    colour = viridis(1, begin = 0.5),
    linewidth = 1) +
  geom_point(
    shape = 21,
    size = 3,
    fill = viridis(1, begin = 0.33),
    alpha = 0.8,
    stroke = 0.5) +
  geom_point(
    data = as.data.table(instance$archive),
    shape = 21,
    size = 3,
    fill = viridis(1, begin = 0.66),
    alpha = 0.8,
    stroke = 0.5) +
  theme_minimal()
```

FIXME: maybe just use sms ego, this is more in line with the SurrogateLearnerCollection introduction earlier

## Noisy Bayesian Optimization {#sec-noisy-bayesian-optimization}

FIXME: Discuss with Bernd if we need this.
HPO is already somehwat noisy.
We could show here that mlr3mbo supports e.g. Augmented EI and different options for choosing the final best points?

## Conclusion

In this chapter, we learned how to use Bayesian Optimization within the mlr3 ecosystem - both for general black-box optimization as well as HPO.
`r mlr3mbo` is built modular relying on a `r ref("Surrogate")`, `r ref("AcqFunction")` and `r ref("AcqOptimizer")` as well as a general `r ref("loop_function")` that build the actual optimizer or tuner constructed in the form of an `r ref("OptimizerMbo")` or `r ref("TunerMbo")`.
A more in-depth introduction to `r mlr3mbo` is given in its getting started vignette.

FIXME: same table as in Tuning? not so interesting here I guess because the relevant classes were menitoned above?

### Resources{.unnumbered .unlisted}

FIXME:

## Exercises

FIXME:

