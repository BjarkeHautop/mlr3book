---
author:
  - name: Martin Binder
    email: martin.binder@stat.uni-muenchen.de
    affiliations:
      - name: Ludwig-Maximilians-Universität München
  - name: Florian Pfisterer
    orcid: 0000-0001-8867-762X
    email: florian.pfisterer@stat.uni-muenchen.de
    affiliations:
      - name: Ludwig-Maximilians-Universität München
  - name: Bernd Bischl
    orcid: 0000-0001-6002-6980
    email: berind.bischl@stat.uni-muenchen.de
    affiliations:
      - name: Ludwig-Maximilians-Universität München
abstract: "
  mlr3 provides a rich interface that abstracts many concepts used for training, predicting, and tuning individual machine learning algorithms.
  However, many real-world machine learning applications involve more than just fitting a single model at a time:
  It is often beneficial or even necessary to preprocess data for feature engineering and compatibility with learners.
  In many cases it is also useful to combine predictions of multiple models in ensembles.

  This chapter introduces mlr3pipelines, a dataflow programming language that can be used to define machine learning processes from simple building blocks.
  After a short demo of the possibilities offered by mlr3pipelines, we describe the individual pipeline operators and how they can be combined, at first in simple and then in more complicated graphs.
  We then show how mlr3pipelines can be used to optimize not only the hyperparameters of learners, but also the hyperparameters of preprocessing operations and even the layout of the dataflow graph itself.
  We give an overview over the most common patterns encountered in graphs and conclude with a section on advanced details and usage.
"
---

# Pipelines {#sec-pipelines}

{{< include _setup.qmd >}}

```{r pipelines-setup, include = FALSE, cache = FALSE}
library("mlr3pipelines")
lgr::get_logger("mlr3")$set_threshold("warn")
lgr::get_logger("bbotk")$set_threshold("warn")
knitr::opts_chunk$set(fig.width=7, fig.height=5, eval = FALSE)
library("data.table")

library("mlr3oml")
dir.create(here::here("book", "openml"), showWarnings = FALSE, recursive = TRUE)
options(mlr3oml.cache = here::here("book", "openml", "cache"))
oldplan = future::plan("multisession")

```

Machine learning (ML) toolkits often try to abstract away the processes inside ML algorithms.
This makes it easy for the user to swap one algorithm for another without having to worry about specifics of each algorithm, what kind of data it is able to operate on etc.
The benefit of using `r ref_pkg("mlr3")`, for example, is that one can use any `r ref("Learner")`, `r ref("Task")`, or `r ref("Resampling")` object and use them for typical ML operations, mostly independently of what algorithms or datasets they represent.
In the following code snippet, it would be trivial to swap in a different learner than `"regr.rpart"` without having to worry about implementation details:
```{r 05-pipelines-in-depth-002, eval = FALSE}
task = as_task_regr(cars, target = "dist")
lrn = lrn("regr.rpart")
rsmp = rsmp("holdout")
resample(task, lrn, rsmp)
```

However, this modularity breaks down as soon as the learning process encompasses more than just model fitting, like data preprocessing, building ensemble-models or even more complicated meta-models.
This is where `r ref_pkg("mlr3pipelines")` [@mlr3pipelines] steps in: it takes modularity one step further than `r mlr3` and makes it possible to build individual steps within a `r ref("Learner")` out of building blocks that manipulate data.
Individual, frequently encountered building blocks, such as missing value imputation or majority vote ensembling, are provided as an (R6-)object, which we call a `r define("PipeOp")`.
These PipeOps can be connected using directed edges inside a `r define("Graph")` (or `r define("Pipeline")`) to represent the flow of data between operations.

Some examples of what can be implemented with `r mlr3pipelines` are:

* Data manipulation and preprocessing operations, e.g. PCA, feature filtering, missing value imputation.
* Task subsampling for speed or for handling of imbalanced classes.
* Ensemble methods and aggregation of predictions.
* Simultaneous model selection and hyperparameter tuning of both learners and preprocessing operators, by using `r mlr3tuning`. This is sometimes facetiously referred to as "CASH", standing for "Combined Algorithm Selection and Hyperparameter optimization" [@Thornton2013].

During model training, the PipeOps in a Graph operate on a given dataset and transform it.
PipeOps that come later in a Graph get the already transformed data as input.
The Graph can therefore be thought of as a network representing function composition.
However, besides transforming data, PipeOps also generate a *state*, similar to how Learners train model parameters.
This state is used to inform the PipeOp's operation during prediction.

As a simple example, consider scaling features to have unit variance `po("scale", center = FALSE)` (@fig-pipelines-state).
During training, it calculates and divides by the standard deviation of each feature.
For prediction, it would be wrong to divide by the standard deviation of the *prediction* dataset; instead the same scaling factors as during training should be used.
The PipeOp therefore stores the scaling factors of each feature in its state, to be used during prediction.
Each PipeOp stores its own state independently of other PipeOps.
A very simple sequential Graph that does various preprocessing operations before fitting a learner is displayed in @fig-pipelines-examples (a).
@fig-pipelines-examples (b) shows a more elaborate pipeline that does alternative path branching.

```{r fig.align='center', eval = TRUE}
#| label: fig-pipelines-state
#| fig-cap: "`$train()` of the \"Scaling\" PipeOp both transfors data (rectangles) as well as creates a state: the scaling factors, necessary to transform data during prediction."
#| fig-alt: "Traning data is transformed by a Scaling PipeOp, which also sets the state inside the PipeOp."
#| out.width: "70%"
#| echo: false
knitr::include_graphics("Figures/state_graphic.svg")
```

When evaluating the performance of an ML process consisting e.g. of preprocessing, followed by model fitting, it is strongly advised to always put the entire preprocessing operation *inside* the resampling loop, as is done here -- `r mlr3pipelines` encourages this more accurate approach.
Making a PCA on the entirety of a dataset, followed by resampling a learner on it, would effectively leak information from the training set to the test set, leading to biased results.

## `r mlr3pipelines` by Example {#sec-pipelines-intro}

In the following, we give a short `r mlr3pipelines` example to give you a quick idea what it is capable of.
The dataflow programming concept implemented by `r mlr3pipelines` is very intuitive, and seeing a few code snippets will already give you a clear idea of how to use it.
In the later chapters we will then explain each of the concepts used in more detail.

```{r eval = TRUE}
#| label: fig-pipelines-examples
#| layout: "[50, 50]"
#| layout-valign: bottom
#| fig-cap: "
#|   Representations of different pipelines.
#|   (a): A simple sequential pipeline that does some preprocessing before feeding data to a learner.
#|   (b): A pipeline that offers three alternative preprocessing paths:
#|   Data can either be scaled, PCA-transformed, or not transformed at all (\"null\") before being fed into the \"classif.rpart\" learner.
#|   By tuning the hyperparameter of the \"branch\" PipeOp, it is possible to discover which preprocessing operation leads to the best performance."
#| fig-subcap:
#|   - Sequential pipeline.
#|   - Alternative path branching pipeline.
#| fig-alt:
#|   - Sequential pipeline that does scaling, factor encoding, and median imputation before fitting a model.
#|   - "Pipeline that feeds data into a \"branch\" operator, followed by, alternatively, \"null\", \"pca\", and \"scale\". Outputs of these are combined into \"unbranch\", followed by \"classif.rpart\"."
#| echo: false
knitr::include_graphics("Figures/single_pipe.svg")

# This just produces a plot, not visible to the user.
library("mlr3pipelines")

graph = po("branch", c("nop", "pca", "scale")) %>>%
  gunion(list(
    po("nop", id = "null1"),
    po("pca"),
    po("scale")
  ))
gr = graph %>>%
  po("unbranch", c("nop", "pca", "scale")) %>>%
  po("learner", lrn("classif.rpart"))

gr$plot()
```

PipeOps can then easily be created using the `r ref("po", "po()")` constructor function.
Just like learners, they have hyperparameters that can be set during construction as well as by using the `$param_set$values` field, as was shown in @sec-training.

```{r pipeop-quickstart-library, eval = TRUE}
library("mlr3pipelines")

pca = po("pca", scale. = TRUE)
```

PipeOps can be combined to form Graphs.
The easiest way to combine PipeOps is to use the `r ref("concat_graphs", "%>>%")`-operator.
To get a Graph that trains a model, combine PipeOps with `r ref("Learner")`.
The `$plot()` method can be used to show what the created Graph looks like.

```{r pipeop-quickstart-graphs-1, eval = TRUE}
gr = pca %>>% lrn("classif.rpart")  # equivalent

gr$plot(horizontal = TRUE)
```

Graphs in which the last operation is a `r ref("PipeOpLearner")` can be turned into a Learner that performs the operations represented by the `Graph` in order by using `r ref("as_learner", "as_learner()")`.
Notice how the decision variables in the model are not the columns of the original dataset, but instead the principal components extracted by the `"pca"`-PipeOp.

```{r pipeop-quickstart-graphlearner-1, eval = TRUE}
gl = as_learner(gr)

gl$train(tsk("iris"))
gl$model$classif.rpart$model
```

The Learner can be `resample()`d, `benchmark()`ed and `tune()`d just as any other `r ref("Learner")`.
```{r pipeop-quickstart-graphlearner-2}
rr = resample(tsk("iris"), gl, rsmp("cv"))
rr$aggregate()
```

<!--
### Non-Sequential `Graph`s

One distinguishing feature of `r mlr3pipelines` is that it can represent Graphs with parallel paths, for example alternative preprocessing operations that then get combined together in a "`cbind`"-operation. To arrange Graphs in parallel, the `r ref("gunion", "gunion()")`-function can be used. The `%>>%` operator tries to automatically connect all outputs of its left hand side to all inputs of its right hand side. The following fits a model on both the centered and the non-centered principal components of the `iris` dataset. The features get combined using the `"featureunion"` PipeOp and then given to the `"classif.rpart"` learner.
```{r pipeop-quickstart-nonseq-1}
gr2 = gunion(list(po("pca", center = TRUE), po("pca", center = FALSE, id = "pca2"))) %>>%
  po("featureunion", innum = c("centered", "noncentered")) %>>% lrn("classif.rpart")
gr2$keep_results = TRUE
gr2$plot()
gl2 = as_learner(gr2)
gl2$train(tsk("iris"))
```
This already shows some advanced usage necessary for this scenario: The ID of one of the `"pca"` PipeOps needs to be changed to avoid name collisions, and the `innum` construction argument of `"featureunion"` is set to a vector of column prefixes to use, as both `"pca"` PipeOps produce columns with the same name.
Setting the`$keep_results` debug-flag of the `Graph` is not necessary, but it allows us to find out what was actually returned by the `"featureunion"` PipeOp during training:
```{r pipeop-quickstart-nonseq-2}
gl2$graph_model$pipeops$featureunion$.result
```
We can also look at the trained `"classif.rpart"`-model to see that both centered as well as noncentered features were used
```{r pipeop-quickstart-nonseq-3}
gl2$model$classif.rpart$model
```

See @sec-pipelines-nonsequential for more on non-sequential Graphs.

### Tuning `GraphLearner`s

`r mlr3pipelines` is well suited for tuning entire ML pipelines.
For one because performance evaluations are more accurate, see above, but also because the constructed Graph objects have a combined hyperparameter space that can be tuned together.
Notice how the hyperparameters of both the `"pca"` PipeOp as well as the `"classif.rpart"` learner are present.
They are prefixed by each object's ID to avoid possible name clashes.

```{r pipeop-quickstart-graphlearner-3}
gl$param_set
```

This `GraphLearner` behaves like any other `r ref("Learner")` for the sake of tuning. The following tunes the number of principal components to use, along with the tree size to use:
```{r pipeop-quickstart-tuning-1}
library("mlr3tuning")
gl$param_set$values$pca.rank. = to_tune(1, 4)
gl$param_set$values$classif.rpart.maxdepth = to_tune(2, 6)

tr = tune(tnr("grid_search"), tsk("iris"), gl, rsmp("cv"))
tr$result
```

@sec-pipelines-tuning gives more details on the topic of tuning Graphs.

### Common `Graph` Patterns

There are various patterns that frequently occur when building ML pipelines that consist of more than just a single PipeOp operation. The `r ref("ppl", "ppl()")` function provides a variety of patterns which are presented in @sec-pipelines-ppl.

The following is an example of *stacking*, using the `"classif.ranger"` and `"classif.multinom"` model predictions as features for a `"classif.rpart"` model:
```{r pipeop-quickstart-ppl-1}
library("mlr3learners")
gr3 = ppl("stacking", lrns(c("classif.ranger", "classif.multinom")), lrn("classif.rpart"))
gr3$plot()
```

-->

## `PipeOp`: Pipeline Operators {#sec-pipelines-pipeops}

The most basic unit of functionality within `r mlr3pipelines` is the `r ref("PipeOp")`, short for "pipeline operator", which represents a transformative operation on input (for example a training dataset) leading to output.
Like a learner, it has a `$train()` and a `$predict()` function, but unlike a learner, these can both return result data.
The training phase will typically generate a certain model of the data that is saved as internal state.
The prediction phase will then operate on the prediction data depending on the trained model.
Therefore, just like a Learner, a PipeOp has "parameters" (i.e. the state) that are trained, but also "hyperparameters" that can be set by the users.
An example of this behavior is the *principal component analysis* operation ("`r ref("PipeOpPCA")`"):
```{r pipeop-intro-1, eval = TRUE}
pca = po("pca")
pca
```
When printed, we can see various things about this PipeOp:
The first line tells us the ID of the PipeOp ("pca") and that it is not trained yet, i.e. it has no `$state`.
The second line would tell us about hyperparameter values.
This is an empty list here, as we are using the default settings of `po("pca")`.
The remaining lines give information about input and output types of this PipeOp.
The PCA PipeOp takes one input (named "`input`") of type "`Task`", both during training and prediction (hence "`[Task,Task]`).
It produces one output (named "`output`"), also of type "`Task`" during both phases.

Training is done using the `$train()`-method.
Unlike the learner's `$train()` method, we can imagine the PipeOp's `$train()` to have multiple inputs, as well as multiple outputs.
This is realized through `list`s: Both the `$train()` input as well as output of a PipeOp is always a `list`; the number of elements that these lists need to have depends on the operation.
The `"pca"` PipeOp, for example, only transforms a single dataset and is therefore called with a list containing a single element, the training data task.
It returns a modified task with features replaced by their principal components.

```{r 05-pipelines-in-depth-003, eval = TRUE}
poin = list(tsk("iris"))
poout = pca$train(poin)
poout
poout[[1]]$data()
```

During training, the PCA transforms incoming data by rotating it in a way that leads to uncorrelated features ordered by their contribution to total variance.
The rotation matrix is also saved to be used for new data during the "prediction phase".
This makes it possible to perform "prediction" with single rows of new data, where a row's scores on each of the principal components (the components of the *training* data!) is computed.

Similarly to `$train()`, the `$predict()` function operates on `list`s:

```{r 05-pipelines-in-depth-004, eval = TRUE}
single_line_iris = tsk("iris")$filter(1)
single_line_iris$data()
poin = list(single_line_iris)
poout = pca$predict(poin)
poout[[1]]$data()
```

The internal state that is trained in the `$train()` call is saved in the `$state` field (shown in @fig-pipelines-state). It can be compared to the `$model` field of a learner, and its content depends on the class of PipeOp being used.

```{r 05-pipelines-in-depth-005, eval = TRUE}
pca$state
```

### Creating `PipeOp`s

Each PipeOp is an instance of an `R6` class, many of which are provided by the `r mlr3pipelines` package itself.
They can be retrieved from the `r ref("mlr_pipeops")` dictionary, most easily by using the `r ref("po", "po()")` short access function.
A shortcut for creating lists of PipeOps from a vector of names is `r ref("pos", "pos()")`.
Besides that, they can also be constructed explicitly ("`PipeOpPCA$new()`").
When retrieving PipeOps from the `r ref("mlr_pipeops")` dictionary, it is also possible to give additional constructor arguments, such as an ID or hyperparameter settings. Setting the ID explicitly is necessary when using multiple instances of the same class of `PipeOp` in a single `Graph`, since otherwise a name collision would occur.

```{r 05-pipelines-in-depth-2-009, eval = TRUE}
po("pca", rank. = 3, id = "pca2")
```

Notice how the printed output for this PipeOp differs from the one shown for `po("pca")` above:
It has a different ID, and the fact that the `rank.` setting differs from the default is also shown.

Some `PipeOp`s, in fact, require construction arguments, for example when they are operators that wrap another `mlr3`-object.
```{r 05-pipelines-pipeops-006, eval = TRUE}
learner = po("learner", learner = lrn("classif.rpart"))
```

Calling `po()` by itself prints all available `PipeOp`s.
You can use `as.data.table(po())` to get a more detailed list with more meta-data.
```{r 06-pipelines-pipeops-006-1, eval = TRUE}
po()
```

## `Graph`: Networks of `PipeOp`s {#sec-pipelines-graphs}

### Basics: Sequential `Graph`s

`PipeOp`s are used to represent individual computational steps in ML pipelines.
These pipelines themselves are defined by `r ref("Graph")` objects.
A Graph is a collection of PipeOps with "edges" that mandate that data should be flowing along them.

It is most convenient to build up a Graph from a sequence of PipeOps, which can be done using the **`r ref("concat_graphs", "%>>%")`** ("double-arrow") operator.
When given two PipeOps, it creates a Graph that executes first the left-hand PipeOp, followed by the right-hand PipeOp.
It can also be used to sequence a Graph with a PipeOp, or with another Graph.
The following example creates a Graph that first adds a `Petal.Area` feature to a given dataset, and then performs scaling and centering of all numeric features.
```{r 05-sequential-01, eval = TRUE}
p_area = po("mutate", mutation = list(Petal.Area = ~Petal.Width * Petal.Length))
p_scale = po("scale")
gr = p_area %>>% p_scale
print(gr)
```

The printer gives information about the layout of the Graph:
For each PipOp (column "ID"), it shows information about its state, as well as a list of its successors ("sccssors", i.e. which PipeOps are connected to its output and come directly after it) and its predecessors ("prdcssors", which PipeOps are connected to its input).
For this simple Graph, we can see that the output of the `mutate` PipeOp is given to the `scale` PipeOp.
While the printer of a Graph gives some information about the layout of a `Graph`, the most intuitive way of visualizing it is using the `$plot()` function.

```{r 05-pipelines-in-depth-017, eval = TRUE}
gr$plot(horizontal = TRUE)
```

### `Graph`s are Nodes with Edges

Internally, Graphs are collections of PipeOps with edges that connect them. 
The collection of PipeOps inside a Graph can be accessed through the `$pipeops` field.
The set of edges in the Graph can be inspected through the `$edges` field.
It is a `data.table` listing the "source" (`src_id`, `src_channel`) and "destination" (`dst_id`, `dst_channel`) of data flowing along each edge.
@sec-pipelines-edges gives advanced details aboud edges.

```{r 05-pipelines-in-depth-018-2, eval = TRUE}
gr$pipeops
gr$edges
```

Besides using the `%>>%`-operator to create Graphs, it is also possible to create them explicitly.
A Graph is empty when first created, and PipeOps can be added using the `$add_pipeop()` method.
The `$add_edge()` method is used to create connections between them.
The above `Graph` can therefore also be created in the following way:

```{r 05-pipelines-in-depth-016, eval = TRUE}
gr = Graph$new()
gr$add_pipeop(p_area)
gr$add_pipeop(p_scale)
gr$add_edge("mutate", "scale")  # address by PipeOp-ID
```

:::{.callout-warning}
Although it is also possible to modify individual PipeOps and edges in a Graph through the `$pipeops` and `$edges` fields, this is not recommended, because no error checking is performed and it may put the Graph in an invalid state.
Only do this if you know what you are doing.
:::

### Using a `Graph`

A Graph itself has a `$train()` and a `$predict()` method that accept some data and propagate this data through the network of PipeOps, by calling their respective `$train()` and `$predict()` methods.
The return value is the output of the PipeOp(s) without outgoing edges.
Just like for PipeOps, the output is a list.

```{r 05-pipelines-in-depth-019, eval = TRUE}
result = gr$train(tsk("iris"))
result
result[[1]]$data()
result = gr$predict(single_line_iris)
result[[1]]$data()
```

### Debugging a `Graph` with Intermediate Results

When Graphs are evaluated, they do not keep intermediate results for memory efficiency, unless the `$keep_results` flag is set first.
Inspecting these results may help understanding the inner workings of Graphs, in particular when they produce unexpected results. 

```{r 05-pipelines-in-depth-021-x, eval = TRUE}
gr$keep_results = TRUE
result = gr$predict(single_line_iris)
intermediate = gr$pipeops$scale$.result
intermediate
intermediate[[1]]$data()
```

## Sequential `Learner`-Pipelines {#sec-pipelines-sequential}

Probably the most common application for `r mlr3pipelines` is to use it to perform basic preprocessing tasks, such as missing value imputation or factor encoding, and to then feed the resulting data into a `r ref("Learner")`.
A Graph representing this workflow manipulates data and fits a `Learner`-model during training, and uses the fitted model with data that was likewise preprocessed during prediction.
Conceptually, the process may look as shown in @fig-pipelines-pipeline.

```{r 05-pipelines-modeling-002, eval = TRUE}
#| label: fig-pipelines-pipeline
#| fig-cap: "Conceptualization of training and prediction process inside a sequential learner-pipeline. During training (top row), the data is passed along the preprocessing operators, each of which modifies the data and creates a `$state`. Finally, the learner receives the data and a model is created. During prediction (bottom row), data is likewise transformed by preprocessing operators, using their respective `$state` information in the process. The learner then receives data that has the same format as the data seen during training, and makes a prediction."
#| fig-alt: "Traning data is transformed by a sequential pipeline during training, being passed along a scaling, factor encoding, and median imputation PipeOp and finally given to a learner. Prediction data is passed along the same pipeline, this time containing state and model objects, to create a prediction."
#| echo: false

knitr::include_graphics("Figures/pipe_action.svg")
```

While a `r ref("Learner")` is not a `r ref("PipeOp")` by itself, it can easily be converted into one using `r ref("as_pipeop", "as_pipeop()")`, or alternatively `po("learner")`, which creates a `r ref("PipeOpLearner")`-wrapper-class.
```{r 05-pipelines-modeling-0, eval = TRUE}
l_rpart = lrn("classif.rpart")
p_rpart = as_pipeop(l_rpart)
p_rpart = po("learner", l_rpart)  # same result
```

However, this is rarely necessary, since the `%>>%`-operator automatically converts Learners to PipeOps. The following code creates a Graph that adds a `Petal.Area` feature, followed by fitting a `"classif.rpart"` decision tree model.

```{r 05-pipelines-modeling-1, eval = TRUE}
p_area = po("mutate", mutation = list(Petal.Area = ~Petal.Width * Petal.Length))
gr = p_area %>>% l_rpart  # could just as well use p_rpart
gr$plot(horizontal = TRUE)
```

To use a Graph as a learner within `r mlr3`, it is necessary to wrap it in a `r ref("GraphLearner")` object, by using `r ref("as_learner", "as_learner()")`.
```{r 05-pipelines-modeling-2, eval = TRUE}
glrn = as_learner(gr)
```

This learner can be used like any other `r ref("Learner")`.
In particular it can be used with `resample()` and `benchmark()`.
Let us compare our sequential pipeline with the `"classif.rpart"`-`Learner` by itself:
```{r 05-pipelines-modeling-3}
grid = benchmark_grid(tsks("iris"), list(glrn, l_rpart), rsmps("repeated_cv"))
bmr = benchmark(grid)
bmr$aggregate()
```

### Accessing Pipeline Objects

The `glrn` variable containing the `GraphLearner` object can be used as an ordinary learner.
However, it is really a wrapper around a Graph, which contains PipeOps, which themselves contain things.
The following demonstrates how the flow of data in a `GraphLearner` can be analyzed.
First, the `$keep_results` flag is set so intermediate results are retained.
The Graph can be accessed through the `$graph_model` field.
```{r 05-pipelines-modeling-debugging, eval = TRUE}
glrn$graph_model$keep_results = TRUE
glrn$train(tsk("iris"))
```

It is now possible to investigate what data was given to the `"classif.rpart"` learner by looking at the output of the `"mutate"`-PipeOp.
As expected, it contains the additional feature `Petal.Area`.
```{r 05-pipelines-modeling-debugging-1, eval = TRUE}
mutate_result = glrn$graph_model$pipeops$mutate$.result
mutate_result
mutate_result[[1]]$data()
```

One can also look at the `$state` of the various PipeOps to investigate the trained model.
Here the trained `"classif.rpart"` classification tree is interesting.
However, it is wrapped inside a `PipeOpLearner`: The trained `Learner` has to be extracted before inspection.
```{r 05-pipelines-modeling-debugging-2, eval = TRUE}
trained_p_rpart = glrn$graph_model$pipeops$classif.rpart
trained_l_rpart = trained_p_rpart$learner_model
trained_l_rpart
trained_l_rpart$model
```

### Pipeline Hyperparameters {#sec-pipelines-hyperparameters}

Just like `r ref("Learner")`s, PipeOps have *hyperparameters* provided by the `r mlr3book::ref_pkg("paradox")` package.
They can be accessed through the `$param_set` field and provide information about the parameters that can be changed.

```{r 05-pipelines-in-depth-032, eval = TRUE}
p_pca = po("pca")
p_pca$param_set
```

Like for `Learner` objects, the `$param_set$values` field can be accessed to change hyperparameter settings; alternatively, hyperparameter values can be given during construction.

```{r 05-pipelines-in-depth-033, eval = TRUE}
p_pca$param_set$values$center = FALSE
# Alternatively:
p_pca = po("pca", center = FALSE)
p_pca$param_set$values
```

Each PipeOp can bring its own individual parameters which are collected together in the Graph's `$param_set`.
A PipeOp's parameter names are prefixed with its ID to prevent parameter name clashes.

```{r 05-pipelines-in-depth-035, eval = TRUE}
gr = p_pca %>>% po("scale", center = TRUE)
gr$param_set
```

When a learner gets encapsulated in a `PipeOpLearner` through `as_pipeop()`, its `ParamSet` is exposed.
When this PipeOp then becomes part of a Graph, the hyperparameters get prefixed with the PipeOp's ID, which is the learner's ID by default.
When a Graph is turned back into a learner using `as_learner()`, the resulting `GraphLearner` retains the Graph's `ParamSet`.
This means, the original learner's hyperparameters are now prefixed with the learner's ID.

```{r 05-pipelines-in-depth-037, eval = TRUE}
l_rpart = lrn("classif.rpart", maxdepth = 2)
l_rpart$param_set$values
p_rpart = as_pipeop(l_rpart)
p_rpart$param_set$values
gr = p_pca %>>% p_rpart
gr$param_set$values
glrn = as_learner(gr)
glrn$param_set$values
```

The hyperparameters of a `GraphLearner` can be changed directly (recommended), but they can also be accessed indirectly by modifying the underlying Graph's, PipeOp's, or learner's hyperparameters.
The following demonstrates the many options:

```{r 05-pipelines-in-depth-038, eval = TRUE}
# modify directly
glrn$param_set$values$classif.rpart.cp = 0.1
# modify Graph
glrn$graph_model$param_set$values$classif.rpart.maxcompete = 10
# modify PipeOp
glrn$graph_model$pipeops$classif.rpart$param_set$values$minbucket = 2
# modify Learner
glrn$graph_model$pipeops$classif.rpart$learner_model$param_set$values$minsplit = 10
glrn$param_set$values
```

### IDs and Name Clashes

To ensure that PipeOps can be accessed by their ID within Graphs, it is necessary that their IDs within a Graph are unique.
IDs can be set during construction using the `id`-argument of `po()`, or they can be changed for existing PipeOps.
For PipeOps that are already in a Graph, the `$set_names()` method can also be used to change IDs, although this should rarely be necessary.

```{r 05-pipelines-in-depth-039, eval = FALSE}
gr = po("pca") %>>% po("pca")
# Error in gunion(list(g1, g2), in_place = c(TRUE, TRUE)) :
# Assertion on 'ids of pipe operators of graphs' failed: Must have unique names, but element 2 is duplicated.
```

```{r 05-pipelines-in-depth-040, eval = TRUE}
gr = po("pca") %>>% po("pca", id = "pca2")
gr
gr$set_names("pca", "pca1")
gr
```

:::{.callout-warning}
Do not change the ID of a PipeOp that is already in a Graph through `graph$pipeops$<old_id>$id = <new_id>`, since this will only change the PipeOp's record of its own ID, not the Graph's record.
The Graph will have undefined behavior in this case.
:::

## Non-Sequential Graphs {#sec-pipelines-nonsequential}

{{< include _optional.qmd >}}

So far, we have shown how simple sequential Graphs can be built from preprocessing PipeOps and encapsulated learners.
We will now show more involved pipelines that can perform more complex operations.

### Parallel `PipeOp`s

Beyond chaining PipeOps sequentially to perform preprocessing operations in order, it is also possible to arrange PipeOps in parallel.
Most Graph layouts can be built using two tools:

* The `gunion()` operation, which takes multiple PipeOps, Graphs, or a mixture of them, and arranges them in parallel, and
* the `%>>%`-operator, which is able to chain Graphs that contain parallel elements, as long as the number of inputs and outputs matches.
  It can even connect a Graph with a single output to a Graph with multiple inputs (the data is distributed to all inputs), or a Graph with multiple outputs to certain special PipeOps with a single input.

The following creates a Graph that first centers its inputs, and then copies the scaled data to two parallel streams: one replaces the data with columns that indicate whether data is missing, the other imputes missing data using the median. The outputs of both streams are then combined into a single dataset using `r ref("PipeOpFeatureUnion")`.

```{r 05-pipelines-modeling-003, fig.width = 8, eval = TRUE}
gr = po("scale", center = TRUE, scale = FALSE) %>>%
  gunion(list(
    po("missind"),
    po("imputemedian")
  )) %>>%
  po("featureunion")
gr$plot(horizontal = TRUE)
```

Processing the first five lines of the "Pima" dataset with this Graph shows how the missing values of the `"insulin"` and `"triceps"` features are handled:
They are imputed, and the corresponding `"missing"`-columns indicate where values were missing.
```{r 05-pipelines-modeling-004, eval = TRUE}
pima_head = tsk("pima")$filter(1:5)
pima_head$data()
result = gr$train(pima_head)
result[[1]]$data()
```

### `PipeOpSelect`, `PipeOpFeatureUnion`, and `affect_columns`

A typical pattern for Graphs is that an operation should be applied to a certain subset of features, but not to another subset.
There are two ways in which this can be realized, as shown in @fig-pipelines-select-affect

1. Many preprocessing PipeOps have an `affect_columns` hyperparameter.
   It can be set so that the PipeOp only operates on a certain subset of columns.
1. One can use the `r ref("PipeOpSelect")` operator in parallel, picking out certain features on which operations should be performed, and unite the result using `r ref("PipeOpFeatureUnion")`.

```{r eval = TRUE}
#| label: fig-pipelines-select-affect
#| layout-nrow: 2
#| fig-cap: "
#|   Two ways of setting up preprocessing operators (`po(op1)` and `po(op2)`) so that they operate on complementary features of an input task.
#|   Both rely on having a `Selector` \"X\", and its complement \"¬X\" = `selector_invert(X)`.
#|   The simpler case, a single operator working only on a subset of all features, is reached by omitting one of `po(op1)` or  `po(op2)`.
#|   (a): The `affect_columns` hyperparameter that many preprocessing PipeOps provide can be used to restrict operations on subsets of features.
#|        PipeOps that should transform complementary features can easily be put in sequence.
#|   (b): Using the `PipeOpSelect` operator, one can remove undesired features, causing subsequent operations to only see the remaining ones.
#|        Here the different subsets of the task are processed on concurrent paths and then combined using a `PipeOpFeatureUnion`.
#|        Note that although the two different `PipeOpSelect` operators have distinct inputs, they are fed the same data if they have the same predecessor in the Graph.
#| "
#| fig-alt:
#|   - "po(op1, affect_columns: X), followed by po(op2, affect_columns: not X)"
#|   - "Two alternative paths, one through po(\"select\", X) and po(op1), another through po(\"select\", not X) and po(op2), both followed by po(\"featureunion\")"
#| fig-subcap:
#|   - Operating on subsets of tasks using `affect_columns`.
#|   - Operating on subset of tasks using concurrent paths and `PipeOpSelect`.
#| out.width: "70%"
#| echo: false
knitr::include_graphics("Figures/affect_pipe.svg")
knitr::include_graphics("Figures/select_pipe.svg")
```

Both of these solutions make use of `r ref("Selector")`-functions.
These are helper-functions that indicate to a PipeOp which features an operation it should apply to.
Straightforward Selectors are, for example, `r ref("selector_grep", "selector_grep()")`, which selects features by name matching a regular expression, or `r ref("selector_type", "selector_type()")`, which selects by type.
Other Selectors can perform set-operations (`r ref("selector_union", "selector_union()")`, `r ref("selector_setdiff", "selector_setdiff()")`) or take all features *not* taken by another Selector (`r ref("selector_invert", "selector_invert()")`).

If one wants to perform PCA on the "Petal"-features of the Iris dataset, but only do scaling on the other features, one would first need a Selector that selects these two columns.
Solving the problem with the `affect_columns` hyperparameter would then work as follows:
```{r 05-pipelines-multicol-1, eval = TRUE}
sel_petal = selector_grep("^Petal")
sel_not_petal = selector_invert(sel_petal)

gr = po("pca", affect_columns = sel_petal) %>>%
  po("scale", affect_columns = sel_not_petal)

result = gr$train(tsk("iris"))
result[[1]]$data()
```

Solving this using parallel paths makes use of the `PipeOpSelect` operator.
It removes all features that are not selected by a given Selector, making it possible to have independent data processing streams for different feature subsets.
Since two `PipeOpSelect` operators are present, it is necessary to give them different IDs to avoid id name clashes.
The solution makes use of the fact that parallel paths all receive copies of the input data when they are at the beginning of a `Graph`.
```{r 05-pipelines-multicol-3, fig.width = 8, eval = TRUE}
gr = gunion(list(
  po("select", id = "sel_petal", selector = sel_petal) %>>% po("pca"),
  po("select", id = "sel_sepal", selector = sel_not_petal) %>>% po("scale")
)) %>>% po("featureunion")
gr$plot(horizontal = TRUE)
```
```{r 05-pipelines-multicol-4, eval = TRUE}
result = gr$train(tsk("iris"))
result[[1]]$data()
```

The advantage of the first method is that it creates a very simple, sequential `Graph`.
However, sometimes it is not possible to perform a desired operation only using `affect_columns`, particularly when the same set of features is used in multiple operations, or when the original features should be kept.
The following, for example, performs PCA on the "Petal" features, but also keeps all original features.
The latter is accomplished using the `r ref("PipeOpNOP")` operator, which does not change its operand.


```{r 05-pipelines-multicol-5, fig.width = 8, eval = TRUE}
gr = gunion(list(
  po("select", id = "sel_petal", selector = sel_petal) %>>% po("pca"),
  po("nop")
)) %>>% po("featureunion")
gr$plot(horizontal = TRUE)
```
```{r 05-pipelines-multicol-6, eval = TRUE}
result = gr$train(tsk("iris"))
result[[1]]$data()
```

### Example: Bagging {#sec-pipelines-bagging}

The basic idea of Bagging, introduced by [@Breiman1996], is to create multiple predictors and then aggregate those to a single, more powerful predictor:

> "... multiple versions are formed
> by making bootstrap replicates of the learning set
> and using these as new learning sets" [@Breiman1996]

Predictions are aggregated by averaging (regression) or majority vote (classification).
The idea behind bagging is that a set of weak, but different (i.e., only weakly correlated) predictors can be combined in order to arrive at a single, better predictor.

We can achieve this by downsampling our data before training a learner, repeating this a number of times, and then performing a majority vote on the predictions.
A schematic is shown in @fig-pipelines-bagging.


```{r eval = TRUE}
#| label: fig-pipelines-bagging
#| fig-cap: "Graph that performs Bagging by independently subsampling data and fitting individual decision tree learners. The resulting predictions are aggregated by a majority vote PipeOp."
#| fig-alt: "Bagging Graph. Data flows through independent subsampling PipeOps and decision tree learners, to be combined by a majority vote PipeOp."
#| out.width: "70%"
#| echo: false
knitr::include_graphics("Figures/nonlinear_pipeops.svg")
```

Although there is a `"bagging"` entry in `r ref("ppl", "ppl()")` that automatically creates a bagging Graph (@sec-pipelines-ppl), it is instructive to think about how bagging can be constructed from scratch, using the building blocks provided by `mlr3pipelines`.
First, we create a simple pipeline that uses `r ref("PipeOpSubsample")` before a learner is trained:

```{r 05-pipelines-non-sequential-009, eval = TRUE}
single_pred = po("subsample", frac = 0.7) %>>% lrn("classif.rpart")
```

We can now copy this operation 10 times using `r ref("pipeline_greplicate", "ppl(\"greplicate\")")`.
`ppl("greplicate")` allows us to parallelize many copies of an operation by creating a Graph containing `n` copies of the input Graph.
Afterwards we need to aggregate the 10 pipelines to form a single model:

```{r 05-pipelines-non-sequential-010, eval = TRUE}
pred_set = ppl("greplicate", graph = single_pred, n = 10)

bagging = pred_set %>>%
  po("classifavg", innum = 10)
```

The following plot shows the layout of the resulting Graph.

```{r 05-pipelines-non-sequential-012, fig.width = 16, eval = TRUE}
bagging$plot(vertex.label.cex = 1)
```

The bagging pipeline can be converted to a learner using `as_learner()`.
The following code compares it to a single `"classif.rpart"`-`Learner`:

```{r 05-pipelines-non-sequential-013}
l_bag = as_learner(bagging)
l_bag$id = "bagging"
l_rpart = lrn("classif.rpart")
grid = benchmark_grid(tsks("iris"), list(l_bag, l_rpart), rsmps("repeated_cv"))
bmr = benchmark(grid)
bmr$aggregate()
```

### Example: `PipeOpLearnerCV` and Stacking {#sec-pipelines-stack}

Stacking [@Wolpert1992] is another technique that can improve model performance.
The basic idea behind stacking is to use of predictions from one model as features for a subsequent model to possibly improve performance.
See @fig-pipelines-stacking for a conceptual illustration.

```{r eval=TRUE, fig.align='center', eval = TRUE}
#| label: fig-pipelines-stacking
#| fig-cap: "Graph that performs Stacking by fitting various models and using their output as features for another model. The `PipeOpLearnerCV` wrapping both a linear model and an SVM will replace the training data by predictions made by these learners. The \"NULL\" (`PipeOpNop`) operation does not change the training data and makes sure that the original features also remain present. Their combined output is given to the feature union PipeOp, which creates a single training task to be given to the Random Forest learner. "
#| fig-alt: "Stacking Graph. Data flows through independent PipeOps fitting both a linear model and an SVM, as well as a NULL operator. Their results all flow into a \"Feature Union\" PipeOp, which gives its result to a \"Random Forest\" `PipeOpLearner`."
#| out.width: "70%"
#| echo: false
knitr::include_graphics("Figures/stacking.svg")
```

Just as for bagging, it is possible to create a stacking pipeline using `ppl()`, as described in @sec-pipelines-ppl, but we show how to construct it manually as an illustrative example.
Here we choose to train a decision tree and add the predictions from this model to the original features.
The resulting dataset is then used to fit an additional model on top.

To limit overfitting, we must create the stacking features from predictions made for data that was not in the training sample.
We therefore use a `r ref("PipeOpLearnerCV")`, wich performs cross-validation on the training data, fitting a model in each fold.
Each of the models is then used to predict on the out-of-fold data.
As a result, we obtain predictions for every data point in our input data.

We first create a learner, which we call the "level 0" learner, which is used to create a feature of predictions.

```{r 05-pipelines-non-sequential-015, eval = TRUE}
l_rpart = lrn("classif.rpart")
lrn_0 = po("learner_cv", l_rpart, id = "rpart_cv")
```

We use `r ref("PipeOpNOP")`, in combination with `r ref("gunion", "gunion()")`, in order to send both the predictions made by the level 0 learner, as well as the unchanged task, to the next level.
There it is combined with the predictions from our decision tree learner.
Afterwards, we concatenate the predictions from `PipeOpLearnerCV` and the original task using `r ref("PipeOpFeatureUnion")`.
We append a final PipeOp containing the learner we want to train on top of the combined features.

```{r 05-pipelines-non-sequential-016, eval = TRUE}
level_0 = gunion(list(lrn_0, po("nop")))
combined = level_0 %>>% po("featureunion")
stack = combined %>>% po("learner", l_rpart)
```

The resulting layout can be visualized by the Graphs `$plot()` function:
```{r 05-pipelines-non-sequential-017, fig.width = 8, eval = TRUE}
stack$plot(horizontal = TRUE)
```

After training this pipeline, we can show that the second `"classif.rpart"` learner used the output of the first `"classif.rpart"` learner as input by inspecting its `$model`.
```{r 05-pipelines-non-sequential-019, eval = TRUE}
l_stack = as_learner(stack)
l_stack$train(tsk("iris"))
l_stack$graph_model$pipeops$classif.rpart$learner_model$model
```

In many real-world applications, stacking is done for multiple levels and on multiple representations of the dataset.
On a lower level, different preprocessing methods can be defined in conjunction with several learners.
On a higher level, we can then combine those predictions in order to form a very powerful model.

## Tuning Graphs {#sec-pipelines-tuning}

Having as many options for preprocessing as `r mlr3pipelines` provides has many benefits, but it also comes with a drawback:
It considerably enlarges the space of possible hyperparameter configurations.
Not only do preprocessing operations bring their own hyperparameter settings, but whether to do preprocessing, and which preprocessing operation to perform, now also needs to be decided.
Tuning ML models with `r mlr3pipelines` comes in three levels of complexity:

1. Tuning the hyperparameters of a Learner or a PipeOp individually when it is part of a Graph.
2. Jointly tuning the hyperparameters of both Learner and its preprocessing operations.
3. Tuning not only the hyperparameters, but also the choice of which operation to perform.

The first level is not much different from tuning individual Learners, as described in @sec-optimization.
The only thing to watch out for here is that a Learner's hyperparameter names are prefixed with its ID, as shown in @sec-pipelines-hyperparameters.
The second level is demonstrated in the following @sec-pipelines-combined.
The third level is also referred to as the "Combined Algorithm Selection and Hyperparameter optimization" (CASH) [@Thornton2013].
It is demonstrated in @sec-pipelines-branch, whish shows how to use alternative path branching.
An alternative way of implementing it is to use `PipeOpProxy`, demonstrated in the (optional) @sec-pipelines-proxy.

In this section, we will use the well-known "MNIST" dataset [@lecun1998gradient], which comprises 28 x 28 pixel images of handwritten digits.
It is a classification task with the goal of identifying the digits accurately.
It is often used to demonstrate deep learning with convolutional layers.
However, in this demonstration, we will not use the information about the relative location of pixels.
Instead, we use each pixel's intensity as a separate feature.
We obtain the data from OpenML, which is described in greater detail in @sec-chapter-openml.
To speed up performance estimation, we subset the given data to 5% of its original size.
```{r 06-pipelines-get-mnist-openml}
library("mlr3oml")
mnist_data = odt(id = 554)
subset = sample(mnist_data$nrow, mnist_data$nrow * 0.05, replace = FALSE)
mnist_task = as_task_classif(mnist_data$data[subset],
    target = "class", id = "mnist")
mnist_task
```


### Tuning Combined Spaces {#sec-pipelines-combined}

Instead of using deep learning, we will use the much simpler k-nearest-neighbor (KNN) learner `lrn("classif.kknn")`.
We use the most widely used variant without kernelization, setting the the `kernel` hyperparameter to `"rectangular"`.
We investigate if doing a principal component analysis using `po("pca")`, and selecting the highest variance components using the `rank.` hyperparameter, can improve performance.
Because the `k` hyperparameter of the KNN learner also needs to be found, we need to tune it simultaneously.

First we need to define the Graph that we tune.
We have the option of setting each component's hyperparameter being tuned to `to_tune()` as is done in @sec-optimization, but here we demonstrate how to define the search space `r ref("ParamSet")` directly.

```{r 05-pipelines-modeling-008}
library("mlr3learners")
glrn = po("pca") %>>%
  lrn("classif.kknn", kernel = "rectangular")
glrn = as_learner(glrn)

library("paradox")
search_space = ps(
  pca.rank. = p_int(lower = 2, upper = mnist_task$ncol, logscale = TRUE),
  classif.kknn.k = p_int(lower = 1, upper = 32, logscale = TRUE)
)
```

We tune this using the `r ref("tune")` function on a 6x6 grid, stepping through both the number of selected principal components (`pca.rank.`) and the KNN's `k` hyperparameter on a log-scale.


```{r debug-dummy, echo=FALSE, eval = TRUE}
instance = list(result_x_domain = list(pca.rank. = 30))
```
```{r 05-pipelines-modeling-009}
library("mlr3tuning")
set.seed(0)
instance = tune(
  method = tnr("grid_search", resolution = 6, batch_size = 100),
  task = mnist_task,
  learner = glrn,
  resampling = rsmp("cv", folds = 3),
  measure = msr("classif.ce"),
  search_space = search_space
)

instance$result
```

:::{.callout-info}
Tuning complex pipelines can become very slow:
Not only are the individual training steps often more complex and therefore take longer; the increased search space dimension usually also means that more evaluations need to be performed to get an acceptable level of performance.
It is therefore recommended to make use of parallelization using `` mlr3book::ref_pkg("future")`, which is demonstrated in @sec-parallelization.
:::


Note that the output values are the log of the actual result, which is:
```{r 05-pipelines-modeling-009-2}
cbind(as.data.table(instance$result_x_domain), classif.ce = instance$result_y)
```

The observed performance values are shown in @fig-pipelines-opttrace-1.
It becomes clear that, for different values of `rank.`, different `k` values can be optimal, so jointly tuning both hyperparameters is prudent.

```{r fig.align='center'}
#| label: fig-pipelines-opttrace-1
#| fig-cap: "Observed performance values when optimizing both `rank.` of `po(\"pca\")` and `k` of `lrn(\"classif.kknn\")` at the same time.
#|   The x-axis shows `k` values (log scale). Each facet (i.e. individual plot) shows the behavior for a different `rank.` value, displayed at the top."
#| fig-alt: "Plot showing performance values of pca, followed by KNN."
#| echo: false
library("ggplot2")
ggplot(instance$archive$data[, c(rbindlist(x_domain), list(classif.ce = classif.ce))], aes(x = classif.kknn.k, y = classif.ce)) +
  geom_line() +
  facet_grid(cols = vars(pca.rank.)) +
  scale_x_log10() +
  theme_bw() +
  labs(title = "Performance of po(\"pca\") %>>% lrn(\"classif.kknn\")")
```

### Tuning Alternative Paths with `PipeOpBranch` {#sec-pipelines-branch}

While we see that tuning the `po("pca")` has benefits, we have not yet seen whether using PCA at all is beneficial.
It is possible that using the tuned PCA simply does the least damage, or that a much simpler operation would perform equally well or better.

Here we can use the `r ref("PipeOpBranch")` and `r ref("PipeOpUnbranch")` POs, which make it possible to specify multiple alternative paths.
Data only flows along one of these paths, which can be controlled by a hyperparameter, as is shown in @fig-pipelines-alternatives (a).
This concept makes it possible to tune alternative preprocessing methods or alternative learner models.

`PipeOp(Un)Branch` is initialized either with the number of branches, or with a `character`-vector indicating the names of the branches.
If names are given, the "branch-choosing" hyperparameter becomes more readable.
In the following, we set three options:

1. Doing nothing ("nop")
2. Applying a PCA
3. Centering and Scaling the data, using `po("scale")`

It is important to "unbranch" again after "branching", so that the outputs are merged into one result objects.

For this demo, we will use the `rank.` value that was the optimum in the last optimization.

```{r 05-pipelines-non-sequential-003, eval = TRUE}
rank_opt = instance$result_x_domain$pca.rank.

graph = po("branch", c("nop", "pca", "scale")) %>>%
  gunion(list(
    po("nop"),
    po("pca", rank. = rank_opt),
    po("scale")
  )) %>>% po("unbranch", c("nop", "pca", "scale"))
```

The resulting graph looks as follows:

```{r 05-pipelines-non-sequential-004, fig.width = 8, eval = TRUE}
graph$plot(horizontal = TRUE)
```

The output of this graph depends on the setting of the `branch.selection` hyperparameter:

```{r 05-pipelines-branch-01}
graph$param_set$values$branch.selection = "pca"  # use the "PCA" path
graph$train(mnist_task)[[1]]$head()
graph$param_set$values$branch.selection = "nop"  # use the "No-Op" path
graph$train(mnist_task)[[1]]$head()
```

Tuning this hyperparameter can be used to determine which of the possible options works best in combination with a given learner.
Branching can even be used to tune which of several learners is most appropriate for a given dataset.
We now extend this example so that both the preprocessing (PCA, scaling, or no preprocessing), as well as the model to use (KNN or decision tree) can be tuned.
For this, we add another branching pathway to our Graph:

```{r 05-pipelines-branch-02, eval = TRUE}
glrn = graph %>>%
  po("branch", c("classif.rpart", "classif.kknn"), id = "branch2") %>>%
    gunion(list(
      lrn("classif.rpart"),
      lrn("classif.kknn", kernel = "rectangular")
    )) %>>%
  po("unbranch", c("classif.rpart", "classif.kknn"), id = "unbranch2")
glrn = as_learner(glrn)
glrn$graph$plot()
```

Note that it is necessary to give the two branching operations different IDs to avoid name clashes.

Finally, we would still like to tune over the `k` hyperparameter of the KNN learner, since it may again depend on the kind of preprocessing being done.
However, this hyperparameter is only active when the "`classif.kknn`" path is chosen.
We therefore have to declare a dependency in the search space.
The search space that tunes over all options of both branching operators as well as the KNN learner's `k` hyperparameter therefore looks like the following:


```{r 05-pipelines-branch-03}
search_space = ps(
  branch.selection = p_fct(c("nop", "pca", "scale")),
  branch2.selection = p_fct(c("classif.rpart", "classif.kknn")),
  classif.kknn.k = p_int(lower = 1, upper = 32, logscale = TRUE,
    depends = branch2.selection == "classif.kknn")
)

set.seed(0)
instance = tune(
  method = tnr("grid_search", resolution = 6, batch_size = 100),
  task = mnist_task,
  learner = glrn,
  resampling = rsmp("cv", folds = 3),
  measure = msr("classif.ce"),
  search_space = search_space
)

cbind(as.data.table(instance$result_x_domain), classif.ce = instance$result_y)
```

<!-- Looking at the result in @fig-pipelines-opttrace-2, we see that the performance of the "nop" path and the "scale" path is the same.
This is not surprising:
By default, the SVM does scaling internally, so the `po("scale")` leads to identical results in this case. -->
Looking at the result, we see that the tuned KNN performs better than the untuned decision tree, "classif.rpart".
A more thorough investigation could try to tune the decision tree to check if its performance can be brought to the level of the KNN algorithm.
Increasing the number of options, however, increases the search space vastly.
The `grid_search` tuner, which we have used here because of its straightforward interpretability, is not recommended for search spaces that have more than a very small number of dimensions.
Therefore, if this investigation were to be carried further, one would need to use a different optimizer, such as random search or Bayesian optimization, the latter of which is demonstrated in @sec-bayesian-optimization.

```{r fig.align='center'}
#| label: fig-pipelines-opttrace-2
#| fig-cap: "Observed performance values when optimizing both preprocessing (between \"pca\", \"scale\", and \"nop\", which is no preprocessing) and Learner (between KNN and the decision tree \"classif.rpart\") at the same time.
#|   The x-axis shows preprocessing. Each facet (i.e. individual plot) shows the Learner being used, together with setting for \"k\", if applicable."
#| fig-alt: "Plot showing performance values of pca, scale, or nop, followed by KNN or decision tree."
#| echo: false

ggplot(instance$archive$data[, learner := ifelse(is.na(classif.kknn.k), "classif.rpart", sprintf("classif.kknn\nk = % 2s", (sapply(x_domain, `[[`, "classif.kknn.k"))))],
  aes(x = branch.selection, y = classif.ce)) +
  geom_point() +
  facet_grid(cols = vars(learner)) +
  theme_bw() +
  labs(title = "Performance of Various Learners with Different Preprocessing")
```

:::{.callout-info}
Graphs with alternative path branching can also be created using `ppl()`, see @sec-pipelines-ppl
:::

### Tuning with `PipeOpProxy` {#sec-pipelines-proxy}

{{< include _optional.qmd >}}

The `r ref("PipeOpProxy")` operator is a meta-operator that performs the operation that is stored in its `content` hyperparameter.
This can either be another PipeOp, or an entire Graph.
Having a PipeOp that can itself contain Graphs that can be tuned over makes it possible to optimize between different PipeOps, similarly to `PipeOpBranch` / `PipeOpUnbranch`.
@fig-pipelines-alternatives shows the conceptual difference between `PipeOpBranch` and `PipeOpProxy`.

```{r eval = TRUE}
#| label: fig-pipelines-alternatives
#| layout-nrow: 2
#| fig-cap: "
#|   Two ways of parametrizing the PipeOps or Learners that should be used.
#|   The setups shown in both examples have the same effect: Data is PCA-transformed before being fed to the learner.
#|   (a): Using `PipeOpBranch` it is possible to choose which one out of various alternative paths should be taken.
#|        In this example, the PCA PipeOp is active, the alternatives (scaling, or no operation through PipeOpNop) are inactive.
#|        A `PipeOpUnbranch` is necessary to mark the end of the alternative paths.
#|   (b): `PipeOpProxy` has the hyperparameter `content`, which can be set to a another PipeOp. In this example, it is set to PCA.
#| "
#| fig-alt:
#|   - "PipeOpBranch, followed by, alternatively, PipeOpNop, PCA, and Scaling, which are all followed by PipeOpUnbranch and a Learner.
#|      The PCA branch is active."
#|   - PipeOpProxy, followed by a Learner. The content of the PipeOpProxy is set to a PCA PipeOp.
#| fig-subcap:
#|   - Usage of `PipeOpBranch`
#|   - Usage of `PipeOpProxy` 
#| out.width: "70%"
#| echo: false
knitr::include_graphics("Figures/branching.svg")
knitr::include_graphics("Figures/proxy.svg")
```

To use `PipeOpProxy` instead of alternative path branching to perform the above optimization, one would first set up a Graph that contains `PipeOpProxy` operators as placeholders for the operations (preprocessing, learning) that should be tuned.
Note the different IDs to avoid a name clash.

```{r}
glrn = po("proxy", id = "preproc") %>>% po("proxy", id = "learner")
glrn = as_learner(glrn)
```

The tuning space for the `content` hyperparameters can now be set to a discrete set of the possibilities that should be tried out.
Using `r ref("p_fct", "paradox::p_fct()")` with a named list of PipeOps that should be inserted works here.
Internally, `r paradox` is creating a transformation function here, see @sec-optimization-trafo for more details.
For the Learner-part, it is necessary to use a more complicated trafo-function, since here the Learner to use depends on more than one search space component.
This is defined here using `.extra_trafo`, which takes the values as generated by the search space as input `x`, and returns the value to be given to the Graph.
The help page of `r ref("ps")` gives more details on this.
Inside this transformation, we need to clone the `learner.content` value before modifying it, since we would otherwise modify the original `Learner` object inside the search space by reference!
Observe how this optimization, when performed with the same seed, has the same result as above.

```{r}
search_space = ps(
  preproc.content = p_fct(list(
    nop = po("nop"),
    pca = po("pca", rank. = rank_opt),
    scale = po("scale")
  )),
  learner.content = p_fct(list(
    classif.rpart = lrn("classif.rpart"),
    classif.kknn = lrn("classif.kknn", kernel = "rectangular")
  )),
  classif.kknn.k = p_int(lower = 1, upper = 32, logscale = TRUE,
    depends = learner.content == "classif.kknn"),
  .extra_trafo = function(x, param_set) {
    if (!is.null(x$classif.kknn.k)) {
      x$learner.content = x$learner.content$clone(deep = TRUE)
      x$learner.content$param_set$values$k = x$classif.kknn.k
      x$classif.kknn.k = NULL
    }
    x
  }
)

set.seed(0)
instance = tune(
  method = tnr("grid_search", resolution = 6, batch_size = 100),
  task = mnist_task,
  learner = glrn,
  resampling = rsmp("cv", folds = 3),
  measure = msr("classif.ce"),
  search_space = search_space
)

as.data.table(instance$result)[,
  .(preproc.content, learner.content,
    classif.kknn.k = x_domain[[1]]$learner.content$param_set$values$k,
    classif.ce)
]
```

##  Common Patterns and `ppl()` {#sec-pipelines-ppl}

{{< include _optional.qmd >}}

There are certain parts of Graphs that often occur in different contexts, but that could not reasonably be provided as single PipeOps by `mlr3pipelines`.
Examples for this were presented in the previous section:
patterns such as alternative paths or stacking are generally useful, but they reflect specific ways of connecting PipeOps instead of singular operations.

There are other commonly occurring problems that are usually solved by a combination of more than one PipeOp.
An example is converting data to make it compatible with a given Learner:
It is often necessary to impute missing values *and* to one-hot-encode categorical features, which are both provided as PipeOps.

We call these frequently needed building blocks "graph elements".
They can be constructed using the `r ref("mlr_graphs")` `Dictionary`.
The best way to access these is the `ppl()` function, which takes a name as its first argument, followed by various other arguments specific to the element being constructed.
The help page for a graph element with name `"<name>"` can be queried as `?ml_graphs_<name>`.

The following is a list of the provided graph elements.
Their mandatory arguments are shown.
They also have optional arguments for fine adjustments which are described on their help page.

* **`r ref("mlr_graphs_robustify", "ppl(\"robustify\")")`**: Perform preprocessing that makes a given `r ref("Task")` compatible with a given `r ref("Learner")`.
  Optional arguments are the `Task` and `Learner` in question, as well as individual switches that decide which kind of preprocessing should be done.
  The "robustify" graph element queries the metadata provided by ghe respective objects and does only the necessary preprocessing.
  E.g., if a given `Learner` has the `"missings"` property (i.e. supports missing values) but does not have `"factor"` in its `$feature_types` (i.e. can not handle categorical features), then `ppl("robustify")` will numerically encode categorical features, but will not do imputation.
* **`r ref("mlr_graphs_branch", "ppl(\"branch\", graphs)")`**: Alternative path branching, as described in @sec-pipelines-branch.
  The mandatory `graphs` argument must be a list of PipeOps or Graphs that should lie on the resulting alternative paths.
  The choice between PCA, scaling, and no-op that is shown in @sec-pipelines-branch can, for example, be produced by calling:
  ```{r, eval = FALSE}
  ppl("branch", graphs = pos(c("pca", "scale", "nop")))
  ```
* **`r ref("mlr_graphs_stacking", "ppl(\"stacking\", base_learners, super_learner)")`**: Stacking, as described in @sec-pipelines-stack. `base_learners` must be a list of learners that are used to augment the incoming data.
  The learner given to `super_learner` is then trained on the original data (unless the optional `use_features` is set to `FALSE`) and the predictions made by these learners.
  The example from @sec-pipelines-stack can thus be written:
  ```{r, eval = FALSE}
  ppl("stacking",
    base_learners = lrns("classif.rpart"),
    super_learner = lrn("classif.rpart")
  )
  ```
* **`r ref("mlr_graphs_bagging", "ppl(\"bagging\", graph)")`**: Bagging, as described in @sec-pipelines-bagging.
  `graph` can be a single learner, but it can also contain a more elaborate pipeline, e.g. involving preprocessing, as long as it produces a prediction at the end.
  Optional parameters control the number of bagging iterations (`iterations`, default 10), the fraction of samples for each bagging learner (`frac`, default 0.7), and the PipeOp doing the aggregation of predictions (`averager`, defaults to simple averaging).
  The bagging pipeline shown in @sec-pipelines-bagging is therefore constructed by calling
  ```{r, eval = FALSE}
  ppl("bagging", graph = lrn("classif.rpart"))
  ```
* **`r ref("mlr_graphs_greplicate", "ppl(\"greplicate\", graph, n)")`**: Create a Graph that contains `n` copies of `graph`.
  `graph` can be a Graph, but can also be a single PipeOp.
  `ppl("greplicate")` in particular takes care of avoiding ID collisions by automatically adding a suffix to each PipeOp that counts up from 1.
  It is particularly useful when building bagging Graphs manually, and an example call is shown in @sec-pipelines-bagging.
* **`r ref("mlr_graphs_targettrafo", "ppl(\"targettrafo\", graph)")`**: Create a Graph that transforms the prediction target of a task.
  The problem with modifying the target column of a task is that a learner that is trained on this task will make predictions relative to the transformed scale.
  It is therefore necessary to perform an additional operation on the predictions made by such a learner which inverts the prediction, bringing them to the original scale.
  The `"targettrafo"` graph element takes care of this.
  The `graph` argument should be the learner or pipeline that should be executed after the target was transformed, but before inversion.
  The transformation / inverter functions are set through the resulting Graph's `$targetmutate.trafo` and `$targetmutate.inverter` hyperparameters.

  The following is an example Graph that log-transforms the target before fitting a linear model, the predictions of which are later exponentiated.
  ```{r, eval = FALSE}
  gr = ppl("targettrafo", graph = lrn("regr.lm"))
  gr$param_set$values$targetmutate.trafo = function(x) log(x)
  gr$param_set$values$targetmutate.inverter = function(x) exp(x)
  ```
* **`r ref("mlr_graphs_ovr", "ppl(\"ovr\", graph)")`**: Do one-versus-rest classification.
  This graph element splits a single multiclass classification task into many binary classification tasks, one for each class in the original task.
  These tasks are then evaluated by the given `graph`, which should be a learner (or a pipeline containing a learner that emits a prediction).

  The predictions made on the binary tasks are then combined into the multiclass prediction needed for the original task.
  If possible, the `$predict_type` of the learner(s) in `graph` should be set to `"prob"`.

  

<!--
TODO: this?

The example above showed a sequential preprocessing pipeline, but it is in fact possible to build true "graphs" of operations, as long as no loops are introduced^[It is tempting to denote this as a "directed acyclic graph", but this would not be entirely correct because edges run between channels of PipeOps, not PipeOps themselves.].
PipeOps with multiple output channels can feed their data to multiple different subsequent PipeOps, and PipeOps with multiple input channels can take results from different PipeOps.
When a PipeOp has more than one input / output channel, then the `r ref("Graph")`'s `$add_edge()` method needs an additional argument that indicates which channel to connect to.
This argument can be given in the form of an integer, or as the name of the channel.

The following constructs a `r ref("Graph")` that copies the input and gives one copy each to a "scale" and a "pca" PipeOp.
The resulting columns of each operation are put next to each other by "featureunion".

```{r 05-pipelines-in-depth-021, tidy = FALSE}
gr = Graph$new()$
  add_pipeop(po("copy", outnum = 2))$
  add_pipeop(po("scale"))$
  add_pipeop(po("pca"))$
  add_pipeop(po("featureunion", innum = 2))

gr$
  add_edge("copy", "scale", src_channel = 1)$        # designating channel by index
  add_edge("copy", "pca", src_channel = "output2")$  # designating channel by name
  add_edge("scale", "featureunion", dst_channel = 1)$
  add_edge("pca", "featureunion", dst_channel = 2)

gr$plot()
```
```{r 05-pipelines-in-depth-022}
# gr$train(iris_first_half)[[1]]$data()
```

### Multilevel Stacking

In order to showcase the power of `r mlr3pipelines`, we will show a more complicated stacking example.

In this case, we train a `r mlr3book::ref_pkg("glmnet")` and 2 different `r mlr3book::ref_pkg("rpart")` models (some transform its inputs using `r ref("PipeOpPCA")`) on our task in the "level 0" and concatenate them with the original features (via `r ref("gunion")`).
The result is then passed on to "level 1", where we copy the concatenated features 3 times and put this task into an `r mlr3book::ref_pkg("rpart")` and a `r mlr3book::ref_pkg("glmnet")` model.
Additionally, we keep a version of the "level 0" output (via `r ref("PipeOpNOP")`) and pass this on to "level 2".
In "level 2" we simply concatenate all "level 1" outputs and train a final decision tree.

In the following examples, use `<lrn>$param_set$values$<param_name> = <param_value>` to set hyperparameters for the different learner.

```{r 05-pipelines-non-sequential-020}
library("magrittr")
library("mlr3learners") # for classif.glmnet

rprt = lrn("classif.rpart", predict_type = "prob")
glmn = lrn("classif.glmnet", predict_type = "prob")

#  Create Learner CV Operators
lrn_0 = po("learner_cv", rprt, id = "rpart_cv_1")
lrn_0$param_set$values$maxdepth = 5L
lrn_1 = po("pca", id = "pca1") %>>% po("learner_cv", rprt, id = "rpart_cv_2")
lrn_1$param_set$values$rpart_cv_2.maxdepth = 1L
lrn_2 = po("pca", id = "pca2") %>>% po("learner_cv", glmn)

# Union them with a PipeOpNULL to keep original features
level_0 = gunion(list(lrn_0, lrn_1, lrn_2, po("nop", id = "NOP1")))

# Cbind the output 3 times, train 2 learners but also keep level
# 0 predictions
level_1 = level_0 %>>%
  po("featureunion", 4) %>>%
  po("copy", 3) %>>%
  gunion(list(
    po("learner_cv", rprt, id = "rpart_cv_l1"),
    po("learner_cv", glmn, id = "glmnt_cv_l1"),
    po("nop", id = "NOP_l1")
  ))

# Cbind predictions, train a final learner
level_2 = level_1 %>>%
  po("featureunion", 3, id = "u2") %>>%
  po("learner", rprt, id = "rpart_l2")

# Plot the resulting graph
level_2$plot()

task = tsk("iris")
lrn = as_learner(level_2)
```

And we can again call `.$train` and `.$predict`:

```{r 05-pipelines-non-sequential-021, warning=FALSE, eval=FALSE}
lrn$
  train(task, train.idx)$
  predict(task, test.idx)$
  score()
```
-->

<!--
## Specific PipeOps

### Imputation: `PipeOpImpute`

Often you will be using data sets that have missing values.
There are many methods of dealing with this issue, from relatively simple imputation using either mean, median or histograms to way more involved methods including using ML algorithms in order to predict missing values.
These methods are called imputation.

The following PipeOps, `r ref("PipeOpImpute")`:

- Add an indicator column marking whether a value for a given feature was missing or not (numeric only)
- Impute numeric values from a histogram
- Impute categorical values using a learner
- We use `po("featureunion")` and `po("nop")` to cbind the missing indicator features. In other words to combine the indicator columns with the rest of the data.

```{r 05-pipelines-special-pipeops-002}
# Imputation example
task = tsk("penguins")
task$missings()

# Add missing indicator columns ("dummy columns") to the Task
pom = po("missind")
# Simply pushes the input forward
nop = po("nop")
# Imputes numerical features by histogram.
pon = po("imputehist", id = "imputer_num")
# combines features (used here to add indicator columns to original data)
pou = po("featureunion")
# Impute categorical features by fitting a Learner ("classif.rpart") for each feature.
pof = po("imputelearner", lrn("classif.rpart"), id = "imputer_fct", affect_columns = selector_type("factor"))
```

Now we construct the graph.

```{r 05-pipelines-special-pipeops-003}
impgraph = list(
  pom,
  nop
) %>>% pou %>>% pof %>>% pon

impgraph$plot()
```

Now we get the new task and we can see that all of the missing values have been imputed.

```{r 05-pipelines-special-pipeops-004}
new_task = impgraph$train(task)[[1]]

new_task$missings()
```

A learner can thus be equipped with automatic imputation of missing values by adding an imputation Pipeop.

```{r 05-pipelines-special-pipeops-005}
polrn = po("learner", lrn("classif.rpart"))
lrn = as_learner(impgraph %>>% polrn)
```

### Feature Engineering: `PipeOpMutate`

New features can be added or computed from a task using `r ref("PipeOpMutate")` .
The operator evaluates one or multiple expressions provided in an `alist`.
In this example, we compute some new features on top of the `iris` task.
Then we add them to the data as illustrated below:

`iris` dataset looks like this:

```{r 05-pipelines-special-pipeops-006}
task = task = tsk("iris")
head(as.data.table(task))
```

Once we do the mutations, you can see the new columns:

```{r 05-pipelines-special-pipeops-007}
pom = po("mutate")

# Define a set of mutations
mutations = list(
  Sepal.Sum = ~ Sepal.Length + Sepal.Width,
  Petal.Sum = ~ Petal.Length + Petal.Width,
  Sepal.Petal.Ratio = ~ (Sepal.Length / Petal.Length)
)
pom$param_set$values$mutation = mutations

new_task = pom$train(list(task))[[1]]
head(as.data.table(new_task))
```

If outside data is required, we can make use of the `env` parameter.
Moreover, we provide an environment, where expressions are evaluated (`env` defaults to `.GlobalEnv`).

### Training on data subsets: `PipeOpChunk`

In cases, where data is too big to fit into the machine's memory, an often-used technique is to split the data into several parts.
Subsequently, the parts are trained on each part of the data.

After undertaking these steps, we aggregate the models.
In this example, we split our data into 4 parts using `r ref("PipeOpChunk")` .
Additionally, we create 4 `r ref("PipeOpLearner")`  POS, which are then trained on each split of the data.

```{r 05-pipelines-special-pipeops-008}
chks = po("chunk", 4)
lrns = ppl("greplicate", po("learner", lrn("classif.rpart")), 4)
```

Afterwards we can use `r ref("PipeOpClassifAvg")` to aggregate the predictions from the 4 different models into a new one.

```{r 05-pipelines-special-pipeops-009}
mjv = po("classifavg", 4)
```

We can now connect the different operators and visualize the full graph:

```{r 05-pipelines-special-pipeops-010, fig.width=7.5, fig.height = 9}
pipeline = chks %>>% lrns %>>% mjv
pipeline$plot()
```

```{r 05-pipelines-special-pipeops-011}
task = tsk("iris")
train.idx = sample(seq_len(task$nrow), 120)
test.idx = setdiff(seq_len(task$nrow), train.idx)

pipelrn = as_learner(pipeline)
pipelrn$train(task, train.idx)$
  predict(task, train.idx)$
  score()
```

### Feature Selection beyond `PipeOpSelect`

When a particular, pre-determined set of features should be selected, the `PipeOpSelect` operator is usually sufficient. However, often it is desirable to select features depending on their relationship with the target variable, for example to create models that rely on only very few features while still being relatively performant. This process is called *feature filtering*.

The package `r mlr3book::ref_pkg("mlr3filters")` contains many different `"mlr3filters::Filter")`s that can be used to select features for subsequent learners.
This is often required when the data has a large amount of features.

A PipeOp for filters is `r ref("PipeOpFilter")`:

```{r 05-pipelines-special-pipeops-012}
po("filter", mlr3filters::flt("information_gain"))
```

How many features to keep can be set using `filter_nfeat`, `filter_frac` and `filter_cutoff`.

## Technical Details

### PipeOp Channels

#### Input Channels

Just like functions, PipeOps can take multiple inputs.
These multiple inputs are always given as elements in the input list.
For example, there is a `r ref("PipeOpFeatureUnion")` that combines multiple tasks with different features and "`cbind()`s" them together, creating one combined task.
When two halves of the `iris` task are given, for example, it recreates the original task:

```{r 05-pipelines-in-depth-009}
iris_first_half = task$clone()$select(c("Petal.Length", "Petal.Width"))
iris_second_half = task$clone()$select(c("Sepal.Length", "Sepal.Width"))

pofu = po("featureunion", innum = 2)

pofu$train(list(iris_first_half, iris_second_half))[[1]]$data()
```

Because `r ref("PipeOpFeatureUnion")` effectively takes two input arguments here, we can say it has two **input channels**.
An input channel also carries information about the *type* of input that is acceptable.
The input channels of the `pofu` object constructed above, for example, each accept a `r ref("Task")` during training and prediction.
This information can be queried from the `$input` field:

```{r 05-pipelines-in-depth-010}
pofu$input
```

Other PipeOps may have channels that take different types during different phases.
The `backuplearner` PipeOp, for example, takes a `NULL` and a `r ref("Task")` during training, and a `r ref("Prediction")` and a `r ref("Task")` during prediction:

```{r 05-pipelines-in-depth-011}
# TODO this is an important case to handle here, do not delete unless there is a better example.
# po("backuplearner")$input
```

#### Output Channels

Unlike the typical notion of a function, PipeOps can also have multiple **output channels**.
`$train()` and `$predict()` always return a list, so certain PipeOps may return lists with more than one element.
Similar to input channels, the information about the number and type of outputs given by a PipeOp is available in the `$output` field.
The `chunk` PipeOp, for example, chunks a given `r ref("Task")` into subsets and consequently returns multiple `r ref("Task")` objects, both during training and prediction.
The number of output channels must be given during construction through the `outnum` argument.

```{r 05-pipelines-in-depth-012}
po("chunk", outnum = 3)$output
```

Note that the number of output channels during training and prediction is the same.
A schema of a PipeOp with two output channels:

```{r 05-pipelines-in-depth-013, echo = FALSE}
knitr::include_graphics("Figures/po_multi_alone.png")
```

#### Channel Configuration

Most PipeOps have only one input channel (so they take a list with a single element), but there are a few with more than one;
In many cases, the number of input or output channels is determined during construction, e.g. through the `innum` / `outnum` arguments.
The `input.num` and `output.num` columns of the `r ref("mlr_pipeops")`-table [above](#where-to-get-pipeops) show the default number of channels, and `NA` if the number depends on a construction argument.

The default printer of a PipeOp gives information about channel names and types:

TODO!!
```{r 05-pipelines-in-depth-014, out.width="98%"}
# po("backuplearner")
```

### Edges {#sec-pipelines-edges}

Edges always pass between PipeOp *channels*, so it is not only possible to explicitly prescribe which position of an input or output list an edge refers to, it makes it possible to make different components of a PipeOp's output flow to multiple different other PipeOps, as well as to have a PipeOp gather its input from multiple other PipeOps.

A schema of a simple graph of PipeOps:

```{r 05-pipelines-in-depth-015, echo = FALSE}
knitr::include_graphics("Figures/po_multi_viz.png")
```

### How `%>>%` Works

-->

```{r pipelines-teardown, include = FALSE, cache = FALSE}
future::plan(oldplan)

```
