\chapter*{Preface}

The \href{https://cran.r-project.org/package=mlr}{\texttt{mlr}}\index{\texttt{mlr}}
package (Bischl et al. 2016) was first released on CRAN in 2013, with
the core design and architecture dating back further. Over time, the
addition of many features led to a complex design that made it too
difficult for us to extend further. In hindsight, we saw that some
design and architecture choices in
\href{https://cran.r-project.org/package=mlr}{\texttt{mlr}} made it
difficult to support new features, in particular with respect to ML
pipelines. So in 2018, we set about working on a reimplementation, which
resulted in the first release of
\href{https://mlr3.mlr-org.com}{\texttt{mlr3}}\index{\texttt{mlr3}} on
CRAN in July 2019.

\subsection*{Overview}

The \texttt{mlr3} ecosystem is the result of many years of
methodological and applied research. This book describes the resulting
features and discusses best practices for ML, technical implementation
details, and in-depth considerations for model optimization. This book
may be helpful for both practitioners who want to quickly apply machine
learning (ML) algorithms and researchers who want to implement,
benchmark, and compare their new methods in a structured environment.
While we hope this book is accessible to a wide range of readers and
levels of ML expertise, we do assume that readers have taken at least an
introductory ML course or have the equivalent expertise and some basic
experience with R. A background in computer science or statistics is
beneficial for understanding the advanced functionality described in the
later chapters of this book, but not required. A comprehensive ML
introduction for those new to the field can be found in James et al.
(2014). Wickham and Grolemund (2017) provides a comprehensive
introduction to data science in R.

The book is split into the following four parts:

\textbf{Part I: Fundamentals} In this part of the book we will teach you
the fundamentals of \texttt{mlr3}. This will give you a flavor of the
building blocks of the \texttt{mlr3} universe and the basic tools you
will need to tackle most machine learning problems. We recommend that
all readers study these chapters to become familiar with \texttt{mlr3}
terminology, syntax, and style. In Chapter~\ref{sec-basics} we will
cover the basic classes in
\href{https://mlr3.mlr-org.com}{\texttt{mlr3}}\index{\texttt{mlr3}},
including \texttt{Learner} (machine learning implementations),
\texttt{Measure} (performance metrics), and \texttt{Task} (machine
learning task definitions). Chapter~\ref{sec-performance} will take
evaluation a step further to include discussions about resampling --
robust strategies for measuring model performance -- and benchmarking --
experiments for comparing multiple models.

\textbf{Part II: Tuning and Feature Selection} In this part of the book,
we will look at more advanced methodology that is essential to
developing powerful ML models with good predictive ability.
Chapter~\ref{sec-optimization} introduces hyperparameter optimization,
which is the process of tuning model hyperparameters to obtain better
model performance. Tuning is implemented via the
\href{https://mlr3tuning.mlr-org.com}{\texttt{mlr3tuning}}\index{\texttt{mlr3tuning}}
package, which also includes methods for automating complex tuning
processes, including nested resampling. The performance of ML models can
be improved by tuning hyperparameters but also by carefully selecting
features. Chapter~\ref{sec-feature-selection} introduces feature
selection with filters and wrappers implemented in
\href{https://mlr3filters.mlr-org.com}{\texttt{mlr3filters}}\index{\texttt{mlr3filters}}
and
\href{https://mlr3fselect.mlr-org.com}{\texttt{mlr3fselect}}\index{\texttt{mlr3fselect}}.
For readers interested in taking a deep dive into tuning,
Chapter~\ref{sec-optimization-advanced} discusses advanced tuning
methods including error handling, multi-objective tuning, and tuning
with Hyperband and Bayesian optimization methods.

\textbf{Part III: Pipelines and Preprocessing} In Part III we introduce
\href{https://mlr3pipelines.mlr-org.com}{\texttt{mlr3pipelines}}\index{\texttt{mlr3pipelines}},
which allows users to implement complex ML workflows easily. In
Chapter~\ref{sec-pipelines} we will show you how to build a pipeline out
of discrete configurable operations and how to treat complex pipelines
as if they were any other machine learning model. In
Chapter~\ref{sec-pipelines-nonseq} we will build on the previous chapter
by introducing non-sequential pipelines, which can have multiple
branches that carry out operations concurrently. We will also
demonstrate how to tune pipelines, including how to tune which
operations should be included in the pipeline. Finally, in
Chapter~\ref{sec-preprocessing} we will put pipelines into practice by
demonstrating how to solve common problems that occur when fitting ML
models to messy data.

\textbf{Part IV: Advanced Topics} In the final part of the book, we will
look at advanced methodology and technical details. This part of the
book is more theory-heavy in some sections to help ground the design and
implementation decisions. We will begin by looking at advanced technical
details in Chapter~\ref{sec-technical} that are essential reading for
advanced users who require parallelization, custom error handling, or
large databases. Chapter~\ref{sec-large-benchmarking} will build on all
preceding chapters to introduce large-scale benchmarking experiments
that compare many models, tasks, and measures; including how to make use
of \texttt{mlr3} extension packages for loading data, using
high-performance computing clusters, and formal statistical analysis of
benchmark experiments. Chapter~\ref{sec-interpretation} will discuss
different packages that are compatible with \texttt{mlr3} to provide
model-agnostic interpretability for feature importance and local
explainability of individual predictions. Chapter~\ref{sec-special} will
then delve into detail on domain-specific methods that are implemented
in our extension packages including survival analysis, density
estimation, spatio-temporal analysis, and more. Readers may choose to
selectively read sections in this chapter depending on your use case
(i.e., if you have domain-specific problems to tackle), or to use these
as introductions to new domains to explore. Finally,
Chapter~\ref{sec-fairness} will introduce algorithmic fairness, which
includes specialized measures and methods to identify and reduce
algorithmic biases.

\subsection*{Citing this book}

This book is the culmination of many years worth of software design,
coding, writing, and editing. It is very important to us that all our
contributors are credited appropriately.

Citation details of packages in the \texttt{mlr3} ecosystem can be found
in their respective GitHub repositories.

When you are citing this book please cite chapters directly; citations
can be found at the end of each chapter. If you need to reference the
full book please use:

\begin{verbatim}
Bischl, B., Sonabend, R., Kotthoff, L., & Lang, M. (Eds.). (2024).
"Applied Machine Learning Using mlr3 in R". CRC Press. https://mlr3book.mlr-org.com

@book{Bischl2024
    title = Applied Machine Learning Using mlr3 in R
    editor = {Bernd Bischl, Raphael Sonabend, Lars Kotthoff, Michel Lang},
    url = {https://mlr3book.mlr-org.com},
    year = {2024},
    isbn = {9781032507545},
    publisher = {CRC Press}
}
\end{verbatim}

Please see the front page of the book website
(\url{https://mlr3book.mlr-org.com}) for full licensing details.

\vspace{10mm}

We hope you enjoy reading this book.

\vspace{5mm}

Bernd, Raphael, Lars, Michel